A **Retrieval-Augmented Generation (RAG)**-powered chatbot that guides users through filing customer complaints via a REST API and answers follow-up questions using a small knowledge base.

---
## High-Level Architecture Overview

                        ┌────────────────────────────┐
                        │      Streamlit Frontend    │
                        │  (streamlit_app.py)        │
                        └────────────┬───────────────┘
                                     │
                                     ▼
                        ┌────────────────────────────┐
                        │   ChatSession (chatbot/)    │
                        │  Handles input logic,       │
                        │  complaint flow, fallback   │
                        │  to RAG if needed           │
                        └────────────┬───────────────┘
                                     │
                ┌────────────────────┴─────────────────────┐
                ▼                                          ▼
    ┌────────────────────────────┐        ┌─────────────────────────────────┐
    │ Complaint API (FastAPI)    │        │   RAG Pipeline (rag_chain.py)   │
    │  POST/GET /complaints      │        │   - Vector store (ObjectBox)    │
    │  CRUD operations on DB     │        │   - HuggingFace embeddings      │
    └────────────┬───────────────┘        │   - LLM (Ollama)                │
                 │                        └──────────────┬──────────────────┘
                 ▼                                         ▼
    ┌────────────────────────────┐        ┌─────────────────────────────────┐
    │    SQLite DB (via ORM)     │        │  Knowledge Store (PDF/TXT/DOCX)│
    │  users, complaints, chats  │        │  data/docs/                     │
    └────────────────────────────┘        └─────────────────────────────────┘

---


## Project Structure

```
project/
├── api/                  # FastAPI complaint + chat endpoints
│   ├── main.py
│   ├── routes.py
│   └── schemas.py
├── core/                 # Database models & logic
│   ├── database.py
│   └── storage.py
├── chatbot/              # RAG chain + conversation flow
│   ├── rag_chain.py
│   └── conversation.py
├── data/                 # Knowledge base files + Object store
│   └── kb/
│       ├── faqs.txt
│       ├── policy.txt
│       └── faiss_store/  # Generated by ingestion
├── scripts/              # One-off ingestion & init scripts
│   └── ingest_kb.py
├── streamlit_app.py      # Streamlit frontend
└── README.md             
```

---

## End-to-End Flow Breakdown

1. Streamlit Frontend (streamlit_app.py)
User interacts via chat interface.
Input is captured and passed to the backend logic.
Displays response messages and chat history.

2. ChatSession Handler (chat_session.py)
Manages conversation state.
Routes query through one of:
Complaint Registration Flow (collects name, phone, email, details).
Complaint Status Retrieval (if user provides complaint ID).
RAG Fallback for generic queries.

3. Complaint Handling (FastAPI api/main.py, routes.py)
Routes:
POST /complaints: Store complaint.
GET /complaints/{id}: Retrieve complaint status.
Uses SQLAlchemy / SQLModel ORM.

4. RAG Logic (rag_chain.py)
Loads:
Embedding model: sentence-transformers/all-MiniLM-L6-v2
Vector store: ObjectBox 
LLM: llama3 via OllamaLLM
Executes Retrieval-Augmented Generation:
Embeds query → retrieves top chunks → builds context → LLM answers.

5. Knowledge Ingestion
Loader script reads .txt, .pdf, .docx.
Splits into chunks, embeds them, and persists to ObjectBox.
Located in data/docs/.

6. Database Layer (core/database.py, core/storage.py)
SQLite database stores:
Complaint records




---



## Architecture & Flow

### 1. **Knowledge Base Ingestion**

* **Input**: Simple `.txt` FAQs and Policy files in `data/kb/`.
* **Processor**:

  * Split text into chunks (300 char, 50 char overlap).
  * Embed with HuggingFace’s all-MiniLM-L6-v2.
  * Store embeddings in ObjectBox vector store (data/objectbox).
  * Script: scripts/ingest_kb.py 
* **Script**: `scripts/ingest_kb.py`

### 2. **FastAPI Backend**

* **Database**: SQLite via SQLModel

  * Table: `Complaint(complaint_id, name, phone_number, email, complaint_details, created_at)`
  * Auto-migrated on startup (`core/database.py` → `init_db()`).
* **API Routes** (`api/routes.py`):

  1. **POST /complaints**

     * Input: `{ name, phone_number, email, complaint_details }`
     * Action: store in DB, generate UUID complaint\_id
     * Output: `{ complaint_id, message }`
  2. **GET /complaints/{complaint\_id}**

     * Fetch details by ID
     * Output: full complaint record + timestamp
  3. **POST /chat**

     * Input: `{ query: string }`
     * Internally uses the **Conversation flow** (below)
     * Output: `{ answer: string, complaint_id?: string }`

### 3. **Conversation Flow** (`chatbot/conversation.py`)

* **States**:

  1. **Collection**

     * Prompts user sequentially for any missing fields:

       1. “Please provide your name.”
       2. “What is your phone number?”
       3. “Please provide your email address.”
       4. “Can you share more details about your complaint?”
  2. **Registration**

     * After all four are collected, calls POST `/complaints`
     * Returns “Your complaint has been registered with ID: XYZ123...”
  3. **Retrieval**

     * If user query contains keywords like “show”/“status” and an ID pattern, calls GET `/complaints/{id}` and returns formatted details.
  4. **RAG Fallback**

     * For any other queries, runs a RAG chain that:

       1. Uses ObjectBox to retrieve top-3 relevant knowledge base chunks..
       2. Prepends these as “Context” in the prompt.
       3. Invokes Ollama LLM (e.g. `llama3`) to generate an answer.

### 4. **Streamlit Frontend** (`streamlit_app.py`)

* A simple chat UI that:

  1. Collects user text via `st.chat_input`.
  2. Shows conversation history.
  3. On “Send”, POSTs `{ query }` to `/chat`.
  4. Displays returned `answer`.
* Sidebar supports fetching complaint status by ID via GET `/complaints/{id}`.

---

## Setup Instructions

### 1. Clone Repo

```bash
git clone https://github.com/yourusername/grievance-rag-chatbot.git
cd grievance-rag-chatbot
```

### 2. Create & Activate Python venv

```bash
python3 -m venv venv
source venv/bin/activate
```

### 3. Install Requirements

```bash
pip install -r requirements.txt
```

### 4. Ingest Knowledge Base

```bash
python scripts/ingest_kb.py
# Verifies `data/faiss_store` is populated
```

### 5. Start FastAPI Backend

```bash
uvicorn api.main:app --reload --port 8000
```

### 6. Run Streamlit Frontend

```bash
streamlit run streamlit_app.py
```

---


 




 

